---
ms.topic: conceptual
ms.service: azure-databricks
ms.reviewer: mamccrea
ms.custom: databricksmigration
ms.author: saperla
author: mssaperla
ms.date: 06/03/2020
title: 带有 Conda (Beta) 的 Databricks Runtime 5.5 - Azure Databricks
description: 关于由 Apache Spark 提供支持的带有 Conda 的 Databricks Runtime 5.5 的发行说明。
ms.openlocfilehash: 75753ff2a0374dd7ce1ef6c3da1692a072dbeb29
ms.sourcegitcommit: 6b499ff4361491965d02bd8bf8dde9c87c54a9f5
ms.translationtype: HT
ms.contentlocale: zh-CN
ms.lasthandoff: 11/06/2020
ms.locfileid: "94329172"
---
# <a name="databricks-runtime-55-with-conda-beta"></a>带有 Conda 的 Databricks Runtime 5.5 (Beta)

> [!NOTE]
>
> 此版本不再可用。 如果要使用 Conda 来管理 Python 库和环境，请使用用于机器学习的 Databricks Runtime 的[受支持版本](releases.md#supported-releases)。

我们非常高兴能引入带有 Conda (Beta) 的 Databricks Runtime 5.5，它可以让你利用 Conda 来管理 Python 库和环境。 此运行时在创建群集时提供两个根 Conda 环境选项：

* **Databricks 标准** 环境包括许多常用 Python 包的更新版本。 此环境旨在临时替代在 Databricks Runtime 上运行的现有笔记本。 这是基于 Databricks Conda 的默认运行时环境。
* **Databricks Minimal** 环境包含 PySpark 和 Databricks Python 笔记本功能所需的最小包数量。 这个环境非常适合使用各种 Python 包来自定义运行时。

两者都包括对 Databricks [库实用工具](../../dev-tools/databricks-utils.md#dbutils-library)的支持。

> [!NOTE]
>
> 带有 Conda 的 Databricks Runtime 5.5 中的 Scala、Java 和 R 库与 Databricks Runtime 5.5 中的相同。 有关详细信息，请参阅 [Databricks Runtime 5.5 LTS](5.5.md) 发行说明。 若要了解如何使用带有 Conda 的 Databricks Runtime，请参阅[带有 Conda 的 Databricks Runtime](../../runtime/conda.md#condaruntime)。

## <a name="new-features"></a>新增功能

提供了一个新的笔记本范围的库 API，以支持使用 YAML 规范更新笔记本的 Conda 环境（请参阅 [Conda 文档](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#create-env-file-manually)）。

```python
dbutils.library.updateCondaEnv('''envYmlContent''')
```

例如，若要将 numpy 库更新到 1.16.4，请调用以下内容：

```python
dbutils.library.updateCondaEnv(
"""channels:
  - default
dependencies:
  - numpy=1.16.4""")
```

> [!NOTE]
>
> 可以使用 `dbutils.library.help("updateCondaEnv")` 获取有关 `updateCondaEnv` 的详细信息。

## <a name="improvements"></a>改进

* 标准环境和最小环境中的包已更新为更新的版本。 有关包版本的完整列表，请参阅[库](#conda55-libraries)。 下面是一些关键包更新：
  * Python 已从 3.7.0 更新至 3.7.3
  * IPython 已从 6.5.0 更新至 7.4.0
  * pip 已从 10.0.1 更新至 19.0.3
* 为了改进笔记本之间的环境隔离，启用了进程隔离和 ADLS 传递。
* 为了让你使用 `conda install` 安装软件包而无需传递容易忘记的 `-y` 标志，现在 `.condarc` 中的 `always_yes` Conda 配置选项已设置为 `True`。

## <a name="system-environment"></a>系统环境

带有 Conda 的 Databricks Runtime 5.5 中的系统环境与 Databricks Runtime 5.5 不同，如下所示：

* **Python**：3.7.x。 仅支持 Python 3。

## <a name="libraries"></a><a id="conda55-libraries"> </a><a id="libraries"> </a>库

下面是带有 Conda 的 Databricks Runtime 5.5 上默认根环境的导出的 `environment.yml` 文件。

### <a name="databricks-standard"></a>Databricks Standard

```yaml
name: databricks-standard
channels:
  - defaults
dependencies:
  - asn1crypto=0.24.0=py37_0
  - backcall=0.1.0=py37_0
  - blas=1.0=openblas
  - boto=2.49.0=py37_0
  - boto3=1.9.162=py_0
  - botocore=1.12.163=py_0
  - ca-certificates=2019.1.23=0
  - certifi=2019.3.9=py37_0
  - cffi=1.12.2=py37h2e261b9_1
  - chardet=3.0.4=py37_1
  - cryptography=2.6.1=py37h1ba5d50_0
  - cython=0.29.6=py37he6710b0_0
  - decorator=4.4.0=py37_1
  - docutils=0.14=py37_0
  - idna=2.8=py37_0
  - ipython=7.4.0=py37h39e3cac_0
  - ipython_genutils=0.2.0=py37_0
  - jedi=0.13.3=py37_0
  - jmespath=0.9.4=py_0
  - krb5=1.16.1=h173b8e3_7
  - libedit=3.1.20181209=hc058e9b_0
  - libffi=3.2.1=hd88cf55_4
  - libgcc-ng=8.2.0=hdf63c60_1
  - libgfortran-ng=7.3.0=hdf63c60_0
  - libopenblas=0.3.6=h5a2b251_0
  - libpq=11.2=h20c2e04_0
  - libstdcxx-ng=8.2.0=hdf63c60_1
  - ncurses=6.1=he6710b0_1
  - nomkl=3.0=0
  - numpy=1.16.2=py37h99e49ec_0
  - numpy-base=1.16.2=py37h2f8d375_0
  - openssl=1.1.1b=h7b6447c_1
  - pandas=0.24.2=py37he6710b0_0
  - parso=0.3.4=py37_0
  - patsy=0.5.1=py37_0
  - pexpect=4.6.0=py37_0
  - pickleshare=0.7.5=py37_0
  - pip=19.0.3=py37_0
  - prompt_toolkit=2.0.9=py37_0
  - psycopg2=2.7.6.1=py37h1ba5d50_0
  - ptyprocess=0.6.0=py37_0
  - pycparser=2.19=py37_0
  - pygments=2.3.1=py37_0
  - pyopenssl=19.0.0=py37_0
  - pysocks=1.6.8=py37_0
  - python=3.7.3=h0371630_0
  - python-dateutil=2.8.0=py37_0
  - pytz=2018.9=py37_0
  - readline=7.0=h7b6447c_5
  - requests=2.21.0=py37_0
  - s3transfer=0.2.0=py37_0
  - scikit-learn=0.20.3=py37h22eb022_0
  - scipy=1.2.1=py37he2b7bc3_0
  - setuptools=40.8.0=py37_0
  - six=1.12.0=py37_0
  - sqlite=3.27.2=h7b6447c_0
  - statsmodels=0.9.0=py37h035aef0_0
  - tk=8.6.8=hbc83047_0
  - traitlets=4.3.2=py37_0
  - urllib3=1.24.1=py37_0
  - wcwidth=0.1.7=py37_0
  - wheel=0.33.1=py37_0
  - xz=5.2.4=h14c3975_4
  - zlib=1.2.11=h7b6447c_3
  - pip:
    - cycler==0.10.0
    - kiwisolver==1.1.0
    - matplotlib==3.0.3
    - pyarrow==0.12.0
    - pyparsing==2.4.0
    - seaborn==0.9.0
prefix: /databricks/conda/envs/databricks-standard
```

### <a name="databricks-minimal"></a>Databricks Minimal

```yaml
name: databricks-minimal
channels:
  - defaults
dependencies:
  - backcall=0.1.0=py37_0
  - blas=1.0=openblas
  - ca-certificates=2019.1.23=0
  - certifi=2019.3.9=py37_0
  - decorator=4.4.0=py37_1
  - ipython=7.4.0=py37h39e3cac_0
  - ipython_genutils=0.2.0=py37_0
  - jedi=0.13.3=py37_0
  - libedit=3.1.20181209=hc058e9b_0
  - libffi=3.2.1=hd88cf55_4
  - libgcc-ng=8.2.0=hdf63c60_1
  - libgfortran-ng=7.3.0=hdf63c60_0
  - libopenblas=0.3.6=h5a2b251_0
  - libstdcxx-ng=8.2.0=hdf63c60_1
  - ncurses=6.1=he6710b0_1
  - nomkl=3.0=0
  - numpy=1.16.2=py37h99e49ec_0
  - numpy-base=1.16.2=py37h2f8d375_0
  - openssl=1.1.1b=h7b6447c_1
  - pandas=0.24.2=py37he6710b0_0
  - parso=0.3.4=py37_0
  - pexpect=4.6.0=py37_0
  - pickleshare=0.7.5=py37_0
  - pip=19.0.3=py37_0
  - prompt_toolkit=2.0.9=py37_0
  - ptyprocess=0.6.0=py37_0
  - pygments=2.3.1=py37_0
  - python=3.7.3=h0371630_0
  - python-dateutil=2.8.0=py37_0
  - pytz=2018.9=py37_0
  - readline=7.0=h7b6447c_5
  - setuptools=40.8.0=py37_0
  - six=1.12.0=py37_0
  - sqlite=3.27.2=h7b6447c_0
  - tk=8.6.8=hbc83047_0
  - traitlets=4.3.2=py37_0
  - wcwidth=0.1.7=py37_0
  - wheel=0.33.1=py37_0
  - xz=5.2.4=h14c3975_4
  - zlib=1.2.11=h7b6447c_3
  - pip:
    - pyarrow==0.12.0
prefix: /databricks/conda/envs/databricks-minimal
```