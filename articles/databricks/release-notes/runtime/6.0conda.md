---
ms.topic: conceptual
ms.service: azure-databricks
ms.reviewer: mamccrea
ms.custom: databricksmigration
ms.author: saperla
author: mssaperla
ms.date: 06/03/2020
title: 带有 Conda 的 Databricks Runtime (Beta) - Azure Databricks 6.0
description: 关于由 Apache Spark 提供支持的带有 Conda 的 Databricks Runtime 6.0 的发行说明。
ms.openlocfilehash: fc8906f123b3aa71832911c4d266529475bc03e8
ms.sourcegitcommit: 6b499ff4361491965d02bd8bf8dde9c87c54a9f5
ms.translationtype: HT
ms.contentlocale: zh-CN
ms.lasthandoff: 11/06/2020
ms.locfileid: "94329433"
---
# <a name="databricks-runtime-60-with-conda-beta"></a>带有 Conda 的 Databricks Runtime 6.0 (Beta)

> [!NOTE]
>
> 此版本不再可用。 如果要使用 Conda 来管理 Python 库和环境，请使用用于机器学习的 Databricks Runtime 的[受支持版本](releases.md#supported-releases)。

带有 Conda 的 Databricks Runtime 6.0 (Beta) 可以让你利用 Conda 来管理 Python 库和环境。 此运行时在创建群集时提供两个 Conda 根环境选项：

* Databricks Standard 环境包括许多常用 Python 包的更新版本。 此环境旨在替代在 Databricks Runtime 上运行的现有笔记本。 这是基于 Databricks Conda 的默认运行时环境。
* Databricks Minimal 环境包含 PySpark 和 Databricks Python 笔记本功能所需的最小数量的包。 这个环境非常适合使用各种 Python 包进行运行时自定义。

两者都包括对 Databricks [库实用工具](../../dev-tools/databricks-utils.md#dbutils-library)的支持。

> [!NOTE]
>
> 带有 Conda 的 Databricks Runtime 6.0 中的 Scala、Java 和 R 库与 Databricks Runtime 6.0 中的相同。 有关详细信息，请参阅 [Databricks Runtime 6.0（不受支持）](6.0.md)发行说明。 有关如何使用带有 Conda 的 Databricks Runtime 的信息，请参阅[带有 Conda 的 Databricks Runtime](../../runtime/conda.md#condaruntime)。

## <a name="new-features"></a>新功能

请参阅 Databricks Runtime 6.0 [新功能](6.0.md#60new-features)。

## <a name="improvements"></a>改进

请参阅 Databricks Runtime 6.0 [改进](6.0.md#60improvements)。

## <a name="bug-fix"></a>Bug 修复

修复了 [Conda 问题 9104（如果“RECORD”文件有重复项，Conda 列表将失败）](https://github.com/conda/conda/issues/9104)。

## <a name="known-issues"></a>已知问题

* 默认情况下，[每个 Python 笔记本都在自己的独立 Conda 环境中运行](../../dev-tools/databricks-utils.md#dbutils-library)。
  此独立环境是从 Conda 根环境克隆的。 由于此克隆是一项代价很高的操作，因此在某些情况下，你可能会遇到以下问题：
  * 如果群集实例类型没有本地存储，则群集创建可能会失败，并出现以下错误：

    ```console
    Could not start Spark. This can happen when installing incompatible libraries or when initialization scripts failed.
    databricks_error_message: Spark failed to start: Timed out after ... seconds
    ```

  * 同时将多个 Python 笔记本附加到单个群集（例如，由计划作业或笔记本工作流触发）可能会导致某些笔记本无法附加。

  如果遇到上述任何问题，并且不需要在独立环境中运行 Python 笔记本（也就是说，你的群集不共享），你可以通过在 [Spark 配置](../../clusters/configure.md#spark-config)中将 `spark.databricks.libraryIsolation.enabled` 设置为 `false` 来禁用为每个 Python 笔记本创建独立 Python 环境。 设置此标志也会禁用 `dbutils.library`。

* 如果升级已安装的 Conda，新版本 Conda 可能不包括 [Conda 问题 9104（如果“RECORD”文件有重复项，Conda 列表将失败）](https://github.com/conda/conda/issues/9104)的修补程序。
  如果升级 Conda 并在驱动程序日志中或笔记本上看到附加 Python 笔记本或使用 `conda list` 时失败并出现错误 `TypeError: '<' not supported between instances of 'NoneType' and 'str'`，请使用带修补程序的 Conda 版本或避免升级此版本中安装的 Conda。

## <a name="system-environment"></a>系统环境

带有 Conda 的 Databricks Runtime 6.0 中的系统环境与 Databricks Runtime 6.0 不同，如下所示：

已安装的 Python 库有一些不同之处。

## <a name="libraries"></a><a id="conda60-libraries"> </a><a id="libraries"> </a>库

下面是带有 Conda 的 Databricks Runtime 6.0 上默认根环境的导出的 `environment.yml` 文件。

### <a name="databricks-standard"></a>Databricks Standard

```yaml
name: databricks-standard
channels:
  - defaults
dependencies:
  - _libgcc_mutex=0.1=main
  - asn1crypto=0.24.0=py37_0
  - backcall=0.1.0=py37_0
  - blas=1.0=openblas
  - boto=2.49.0=py37_0
  - boto3=1.9.162=py_0
  - botocore=1.12.163=py_0
  - ca-certificates=2019.1.23=0
  - certifi=2019.3.9=py37_0
  - cffi=1.12.2=py37h2e261b9_1
  - chardet=3.0.4=py37_1003
  - cryptography=2.6.1=py37h1ba5d50_0
  - cython=0.29.6=py37he6710b0_0
  - decorator=4.4.0=py37_1
  - docutils=0.14=py37_0
  - idna=2.8=py37_0
  - ipython=7.4.0=py37h39e3cac_0
  - ipython_genutils=0.2.0=py37_0
  - jedi=0.13.3=py37_0
  - jmespath=0.9.4=py_0
  - krb5=1.16.1=h173b8e3_7
  - libedit=3.1.20181209=hc058e9b_0
  - libffi=3.2.1=hd88cf55_4
  - libgcc-ng=8.2.0=hdf63c60_1
  - libgfortran-ng=7.3.0=hdf63c60_0
  - libopenblas=0.3.6=h5a2b251_1
  - libpq=11.2=h20c2e04_0
  - libstdcxx-ng=8.2.0=hdf63c60_1
  - ncurses=6.1=he6710b0_1
  - nomkl=3.0=0
  - numpy=1.16.2=py37h99e49ec_0
  - numpy-base=1.16.2=py37h2f8d375_0
  - openssl=1.1.1b=h7b6447c_1
  - pandas=0.24.2=py37he6710b0_0
  - parso=0.3.4=py37_0
  - patsy=0.5.1=py37_0
  - pexpect=4.6.0=py37_0
  - pickleshare=0.7.5=py37_0
  - pip=19.0.3=py37_0
  - prompt_toolkit=2.0.9=py37_0
  - psycopg2=2.7.6.1=py37h1ba5d50_0
  - ptyprocess=0.6.0=py37_0
  - pycparser=2.19=py37_0
  - pygments=2.3.1=py37_0
  - pyopenssl=19.0.0=py37_0
  - pysocks=1.6.8=py37_0
  - python=3.7.3=h0371630_0
  - python-dateutil=2.8.0=py37_0
  - pytz=2018.9=py37_0
  - readline=7.0=h7b6447c_5
  - requests=2.21.0=py37_0
  - s3transfer=0.2.1=py37_0
  - scikit-learn=0.20.3=py37h22eb022_0
  - scipy=1.2.1=py37he2b7bc3_0
  - setuptools=40.8.0=py37_0
  - six=1.12.0=py37_0
  - sqlite=3.27.2=h7b6447c_0
  - statsmodels=0.9.0=py37h035aef0_0
  - tk=8.6.8=hbc83047_0
  - traitlets=4.3.2=py37_0
  - urllib3=1.24.1=py37_0
  - wcwidth=0.1.7=py37_0
  - wheel=0.33.1=py37_0
  - xz=5.2.4=h14c3975_4
  - zlib=1.2.11=h7b6447c_3
  - pip:
    - cycler==0.10.0
    - kiwisolver==1.1.0
    - matplotlib==3.0.3
    - pyarrow==0.13.0
    - pyparsing==2.4.2
    - seaborn==0.9.0
prefix: /databricks/conda/envs/databricks-standard
```

### <a name="databricks-minimal"></a>Databricks Minimal

```yaml
name: databricks-minimal
channels:
  - defaults
dependencies:
  - _libgcc_mutex=0.1=main
  - backcall=0.1.0=py37_0
  - blas=1.0=openblas
  - ca-certificates=2019.1.23=0
  - certifi=2019.3.9=py37_0
  - decorator=4.4.0=py37_1
  - ipython=7.4.0=py37h39e3cac_0
  - ipython_genutils=0.2.0=py37_0
  - jedi=0.13.3=py37_0
  - libedit=3.1.20181209=hc058e9b_0
  - libffi=3.2.1=hd88cf55_4
  - libgcc-ng=8.2.0=hdf63c60_1
  - libgfortran-ng=7.3.0=hdf63c60_0
  - libopenblas=0.3.6=h5a2b251_1
  - libstdcxx-ng=8.2.0=hdf63c60_1
  - ncurses=6.1=he6710b0_1
  - nomkl=3.0=0
  - numpy=1.16.2=py37h99e49ec_0
  - numpy-base=1.16.2=py37h2f8d375_0
  - openssl=1.1.1b=h7b6447c_1
  - pandas=0.24.2=py37he6710b0_0
  - parso=0.3.4=py37_0
  - pexpect=4.6.0=py37_0
  - pickleshare=0.7.5=py37_0
  - pip=19.0.3=py37_0
  - prompt_toolkit=2.0.9=py37_0
  - ptyprocess=0.6.0=py37_0
  - pygments=2.3.1=py37_0
  - python=3.7.3=h0371630_0
  - python-dateutil=2.8.0=py37_0
  - pytz=2018.9=py37_0
  - readline=7.0=h7b6447c_5
  - setuptools=40.8.0=py37_0
  - six=1.12.0=py37_0
  - sqlite=3.27.2=h7b6447c_0
  - tk=8.6.8=hbc83047_0
  - traitlets=4.3.2=py37_0
  - wcwidth=0.1.7=py37_0
  - wheel=0.33.1=py37_0
  - xz=5.2.4=h14c3975_4
  - zlib=1.2.11=h7b6447c_3
  - pip:
    - pyarrow==0.13.0
prefix: /databricks/conda/envs/databricks-minimal
```